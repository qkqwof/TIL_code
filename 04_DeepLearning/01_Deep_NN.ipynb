{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 프레임워크 불러오는 부분\n",
    "import torch\n",
    "import torchvision # image processing에 특화된 라이브러리\n",
    "import torch.nn as nn # neural network\n",
    "import torchvision.transforms as transforms # Data Augmentation 특화된 라이브러리\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.Tensor(2,3) # 2행 3열의 텐서를 하나 생성\n",
    "X.shape\n",
    "X.size()\n",
    "\n",
    "X = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor(2,3)\n",
    "X.shape\n",
    "X.size()\n",
    "\n",
    "X = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tensor()인자값으로\n",
    "data : 값지정, 초기화\n",
    "dtype\n",
    "requires_grad : tensor에 대해서 미분 적용할지 여부\n",
    "'''\n",
    "\n",
    "x = torch.tensor(data=[2.0,3.0], requires_grad=True) # 입력값\n",
    "x\n",
    "\n",
    "y = x**2 # 4, 9 \n",
    "y\n",
    "\n",
    "pred = 2*y + 3 # 11, 21 -> 예측값\n",
    "\n",
    "target = torch.tensor([3.0,4.0]) # 3, 4 -> 타겟\n",
    "target\n",
    "\n",
    "#예측에서 정답을 빼면 loss\n",
    "#loss = (11-3)+(21-4) = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(data=[2.0,3.0], requires_grad=True)\n",
    "x\n",
    "\n",
    "y = x**2\n",
    "y\n",
    "\n",
    "pred = 2*y + 3\n",
    "\n",
    "target = torch.tensor([3.0,4.0])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "위에 나온 결과를 바탕으로\n",
    "경사하강법을 이용해서 \n",
    "미분을 사용해서 Loss에 대한 책임을 묻겠다\n",
    "기울기가 계산이 될 것이다.(미분 계산)\n",
    "--> BackPropagation 을 적용하려면 backward() 함수를 호출\n",
    "\n",
    "Loss를 줄여나가 보겠다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss tensor(25., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.sum(torch.abs(pred - target))\n",
    "print('Loss',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 12.]) None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-f0cd9ca8c1fa>:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  print(x.grad,pred.grad)\n"
     ]
    }
   ],
   "source": [
    "print(x.grad,pred.grad) # 기울기 계산이 안됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tesor...Using NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2874, -1.5762, -1.5403],\n",
      "        [ 0.5376,  2.0259, -0.8607],\n",
      "        [ 1.0645, -0.1771, -0.9113],\n",
      "        [ 1.2170, -0.3671, -1.0788],\n",
      "        [ 1.0456,  0.9344,  0.0431],\n",
      "        [ 0.2603, -0.4910,  0.3295],\n",
      "        [-0.6879,  1.3867, -0.2419],\n",
      "        [ 0.3960,  0.8492,  0.2218],\n",
      "        [ 0.8542, -0.8396, -0.9596],\n",
      "        [-0.2468,  0.5085, -0.3830]])\n",
      "tensor([[-0.4198, -0.0186],\n",
      "        [-0.6257, -0.8362],\n",
      "        [-0.3832, -0.2261],\n",
      "        [-0.6525,  1.6509],\n",
      "        [ 0.4967, -1.0812],\n",
      "        [-0.1631, -0.0754],\n",
      "        [ 1.7628, -0.3099],\n",
      "        [ 1.0655, -0.4675],\n",
      "        [ 0.0854, -2.1135],\n",
      "        [ 0.8530,  0.2630]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10,3)\n",
    "y = torch.randn(10,2)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w Parameter containing:\n",
      "tensor([[ 0.3471, -0.5402,  0.0516],\n",
      "        [ 0.5423, -0.1827,  0.2582]], requires_grad=True)\n",
      "b Parameter containing:\n",
      "tensor([0.1059, 0.4946], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(3,2)\n",
    "print(\"w\",linear.weight)\n",
    "print(\"b\",linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001E73EB4E4A0>\n",
      "loss before step BackPropagation 1.6401102542877197\n"
     ]
    }
   ],
   "source": [
    "# 객체 출력, parameters()함수는 모델 안의 학습의 주체인 w,b를 내포하고 있는 객체\n",
    "# parameters() 함수는 w,b를 해킹한 함수\n",
    "print(linear.parameters())\n",
    "\n",
    "# loss function을 미리 선정의 해두었다.\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# optimizer(하산하는 방법)를 미리 정의\n",
    "optimizer = torch.optim.SGD(linear.parameters(),lr=0.01)\n",
    "\n",
    "# 위에서 만든 모델에 값을 입력...결과로 예측값이 나온다.\n",
    "pred = linear(x)\n",
    "\n",
    "# 정답과 예측값을 이용해서 위에서 선정의한 Loss를 계산...L(W)\n",
    "loss = loss_function(pred, y)\n",
    "print(\"loss before step BackPropagation\",loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw tensor([[ 0.3946, -0.9733, -0.3620],\n",
      "        [ 0.6005,  0.1710, -0.3734]])\n",
      "dL/db tensor([-0.1013,  0.8611])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "loss값이 나왔다는 것은\n",
    "모델의 예측값에 대한 잘잘못을 정량화 했다는 것이다.\n",
    "\n",
    "이 값을 바탕으로 BackPropagation을 하면 w, b에 대한 미분값\n",
    "즉 얼마만큼 보정해야 하는지의 값이 나온다.\n",
    "그 값을 이용해서 다시 하강(기울기 수정)하기 때문에\n",
    "2번쨰에는 Loss가 줄어들어야 한다.\n",
    "'''\n",
    "\n",
    "loss.backward() # loss값에 대한 w에 책임을 묻는다...미분을 적용. grad\n",
    "print(\"dL/dw\", linear.weight.grad)\n",
    "print(\"dL/db\", linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after BackPropagation :  1.6151301860809326\n"
     ]
    }
   ],
   "source": [
    "optimizer.step() # 위에서 수정된 값으로 하강을 진행한다...학습을 한다\n",
    "\n",
    "# 반복효과\n",
    "pred = linear(x)\n",
    "loss = loss_function(pred,y)\n",
    "\n",
    "print(\"loss after BackPropagation : \",loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
