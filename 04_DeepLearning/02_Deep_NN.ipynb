{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1 # 1차원 데이터\n",
    "output_size = 1 # 1차원 데이터\n",
    "num_epochs = 200 # 학습횟수\n",
    "learing_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7  ],\n",
       "       [2.76 ],\n",
       "       [2.09 ],\n",
       "       [3.19 ],\n",
       "       [1.694],\n",
       "       [1.573],\n",
       "       [3.366],\n",
       "       [2.596],\n",
       "       [2.53 ],\n",
       "       [1.221],\n",
       "       [2.827],\n",
       "       [3.465],\n",
       "       [1.65 ],\n",
       "       [2.904],\n",
       "       [1.3  ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168], \n",
    "                    [9.779], [6.182], [7.59], [2.167], [7.042], \n",
    "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573], \n",
    "                    [3.366], [2.596], [2.53], [1.221], [2.827], \n",
    "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)\n",
    "\n",
    "x_train\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. 모델 생성\\n2. loss, optimizer 선정의\\n3. 모델에 데이터를 입력하고 그 결과로 예측값을 반환 받는다.\\n4. 예측값이 반환되면 Loss를 알 수 있다.(이때 2번에 미리 정의된 loss 함수를 호출)\\n5. loss.backward() --> Loss에 대한 책임을 W에게 묻는다() --> w 여러개면 편미분이 적용\\n6. 5번의 결과를 가지고 학습을 진행\\n\\n3~6번의 과정을 총 100번 진행한다. num_epochs = 100\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. 모델 생성\n",
    "2. loss, optimizer 선정의\n",
    "3. 모델에 데이터를 입력하고 그 결과로 예측값을 반환 받는다.\n",
    "4. 예측값이 반환되면 Loss를 알 수 있다.(이때 2번에 미리 정의된 loss 함수를 호출)\n",
    "5. loss.backward() --> Loss에 대한 책임을 W에게 묻는다() --> w 여러개면 편미분이 적용\n",
    "6. 5번의 결과를 가지고 학습을 진행\n",
    "\n",
    "3~6번의 과정을 총 100번 진행한다. num_epochs = 100\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(input_size,output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_Function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learing_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Loss : 6.856633\n",
      "Epoch [10/200], Loss : 3.043547\n",
      "Epoch [15/200], Loss : 1.498382\n",
      "Epoch [20/200], Loss : 0.871987\n",
      "Epoch [25/200], Loss : 0.617802\n",
      "Epoch [30/200], Loss : 0.514407\n",
      "Epoch [35/200], Loss : 0.472100\n",
      "Epoch [40/200], Loss : 0.454542\n",
      "Epoch [45/200], Loss : 0.447012\n",
      "Epoch [50/200], Loss : 0.443544\n",
      "Epoch [55/200], Loss : 0.441724\n",
      "Epoch [60/200], Loss : 0.440572\n",
      "Epoch [65/200], Loss : 0.439692\n",
      "Epoch [70/200], Loss : 0.438924\n",
      "Epoch [75/200], Loss : 0.438201\n",
      "Epoch [80/200], Loss : 0.437498\n",
      "Epoch [85/200], Loss : 0.436804\n",
      "Epoch [90/200], Loss : 0.436115\n",
      "Epoch [95/200], Loss : 0.435429\n",
      "Epoch [100/200], Loss : 0.434745\n",
      "Epoch [105/200], Loss : 0.434062\n",
      "Epoch [110/200], Loss : 0.433382\n",
      "Epoch [115/200], Loss : 0.432704\n",
      "Epoch [120/200], Loss : 0.432027\n",
      "Epoch [125/200], Loss : 0.431352\n",
      "Epoch [130/200], Loss : 0.430679\n",
      "Epoch [135/200], Loss : 0.430007\n",
      "Epoch [140/200], Loss : 0.429338\n",
      "Epoch [145/200], Loss : 0.428670\n",
      "Epoch [150/200], Loss : 0.428003\n",
      "Epoch [155/200], Loss : 0.427339\n",
      "Epoch [160/200], Loss : 0.426676\n",
      "Epoch [165/200], Loss : 0.426014\n",
      "Epoch [170/200], Loss : 0.425355\n",
      "Epoch [175/200], Loss : 0.424697\n",
      "Epoch [180/200], Loss : 0.424041\n",
      "Epoch [185/200], Loss : 0.423387\n",
      "Epoch [190/200], Loss : 0.422734\n",
      "Epoch [195/200], Loss : 0.422083\n",
      "Epoch [200/200], Loss : 0.421433\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(input_size,output_size)\n",
    "\n",
    "loss_Function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learing_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "    \n",
    "    pred = model(inputs)\n",
    "    loss = loss_Function(pred,targets)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(\"Epoch [{}/{}], Loss : {:4f}\".format(epoch+1,num_epochs,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/200], Loss :0.420785\n",
      "Epoch[10/200], Loss :0.420139\n",
      "Epoch[15/200], Loss :0.419495\n",
      "Epoch[20/200], Loss :0.418852\n",
      "Epoch[25/200], Loss :0.418211\n",
      "Epoch[30/200], Loss :0.417571\n",
      "Epoch[35/200], Loss :0.416934\n",
      "Epoch[40/200], Loss :0.416297\n",
      "Epoch[45/200], Loss :0.415663\n",
      "Epoch[50/200], Loss :0.415030\n",
      "Epoch[55/200], Loss :0.414398\n",
      "Epoch[60/200], Loss :0.413769\n",
      "Epoch[65/200], Loss :0.413141\n",
      "Epoch[70/200], Loss :0.412514\n",
      "Epoch[75/200], Loss :0.411889\n",
      "Epoch[80/200], Loss :0.411266\n",
      "Epoch[85/200], Loss :0.410644\n",
      "Epoch[90/200], Loss :0.410024\n",
      "Epoch[95/200], Loss :0.409406\n",
      "Epoch[100/200], Loss :0.408789\n",
      "Epoch[105/200], Loss :0.408173\n",
      "Epoch[110/200], Loss :0.407560\n",
      "Epoch[115/200], Loss :0.406947\n",
      "Epoch[120/200], Loss :0.406337\n",
      "Epoch[125/200], Loss :0.405728\n",
      "Epoch[130/200], Loss :0.405120\n",
      "Epoch[135/200], Loss :0.404514\n",
      "Epoch[140/200], Loss :0.403910\n",
      "Epoch[145/200], Loss :0.403307\n",
      "Epoch[150/200], Loss :0.402706\n",
      "Epoch[155/200], Loss :0.402106\n",
      "Epoch[160/200], Loss :0.401508\n",
      "Epoch[165/200], Loss :0.400911\n",
      "Epoch[170/200], Loss :0.400316\n",
      "Epoch[175/200], Loss :0.399723\n",
      "Epoch[180/200], Loss :0.399131\n",
      "Epoch[185/200], Loss :0.398540\n",
      "Epoch[190/200], Loss :0.397951\n",
      "Epoch[195/200], Loss :0.397363\n",
      "Epoch[200/200], Loss :0.396777\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs): # 100번 학습한다...for를 100번 반복\n",
    "    # numpy arrays를 torch의 Tensor로 만들어서 머신에 입력해야 한다.\n",
    "    inputs = torch.from_numpy(x_train) # X\n",
    "    targets = torch.from_numpy(y_train) # y\n",
    "    \n",
    "    #Forward Pass\n",
    "    pred = model(inputs)\n",
    "    loss = loss_Function(pred,targets)\n",
    "    \n",
    "    #Backward and Optimization\n",
    "    optimizer.zero_grad() # 기존의 값을 초기화(optimizer값) # 이 부분 가장 먼저 나와야 함\n",
    "    loss.backward()\n",
    "    optimizer.step() # 학습 진행\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(\"Epoch[{}/{}], Loss :{:4f}\".format(epoch+1,num_epochs,loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 할 때는 Tensor에서 Numpy로 다시 만들어줘야 한다.\n",
    "predict = model(torch.from_numpy(x_train)).detach().numpy()\n",
    "\n",
    "plt.plot(x_train, y_train,'ro',label=\"Original Data\")\n",
    "plt.plot(x_train, predict,label = \"Predict Line\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "torch.save(model.state_dict(),\"model.ckpt\") #모델이 학습한 w값이 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
