{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 함수\n",
    "\n",
    "$$\n",
    "Y = Wx + b\n",
    "$$\n",
    "\n",
    "x는 특성, y는 예측 값이다. \n",
    "W는 기울기, b는 y절편을 뜻하지만 W는 가중치(weight), b는 offset으로 부를 수도 있다.\n",
    "선형 회귀에서는 여러 샘플의 특성 값과 예측 값을 활용해 가장 적절한 w와 b를 구하는 것이 목적이다.\n",
    "### 평균 제곱 오차 (Mean Square Error)\n",
    "선형 회귀에서는 Coast 함수(또는 비용 함수)로 평균 제곱 오차를 사용한다. \n",
    "여기서 Coast 함수란 샘플 데이터와 타깃과의 유사도를 의미하며 Coast 함수가 최소가 되도록 \n",
    "파라미터를 학습시킨다. \n",
    "$$\n",
    "   \\frac{1}{n}\\sum(pred_i - y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1., 2., 3., 4., 5., 6.])\n",
    "Y = np.array([9., 16., 23., 30., 37., 44.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W, B값은 0으로 초기화 되어져 있습니다.\n",
    "W = 0.0\n",
    "b = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data = len(X)\n",
    "n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000 # 전체 데이터 셋에 대해 한 번 학습을 하는 사이클을 의미한다.\n",
    "learning_rate = 0.01 #학습속도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "    아랫 부분은 머신러닝 알고리즘을 활용하여 \n",
    "    전체 EPOCH 을 돌면서 가장 Cost가 낮은 W,B값을 찾아서 예측값을 출력해보세요\n",
    "    이때 위에 있는 MSE 함수 원리는 그대로 적용한 코드를 만들어서 손실 부분을 \n",
    "    계산하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch (         0 /       5000) cost:  0.045121, W:  7.044374,b:  1.665509\n",
      "Epoch (       100 /       5000) cost:  0.014333, W:  7.063633,b:  1.727575\n",
      "Epoch (       200 /       5000) cost:  0.009947, W:  7.053011,b:  1.773051\n",
      "Epoch (       300 /       5000) cost:  0.006904, W:  7.044162,b:  1.810936\n",
      "Epoch (       400 /       5000) cost:  0.004791, W:  7.036790,b:  1.842496\n",
      "Epoch (       500 /       5000) cost:  0.003325, W:  7.030648,b:  1.868789\n",
      "Epoch (       600 /       5000) cost:  0.002308, W:  7.025532,b:  1.890692\n",
      "Epoch (       700 /       5000) cost:  0.001601, W:  7.021270,b:  1.908939\n",
      "Epoch (       800 /       5000) cost:  0.001111, W:  7.017719,b:  1.924140\n",
      "Epoch (       900 /       5000) cost:  0.000771, W:  7.014761,b:  1.936803\n",
      "Epoch (      1000 /       5000) cost:  0.000535, W:  7.012297,b:  1.947353\n",
      "Epoch (      1100 /       5000) cost:  0.000372, W:  7.010245,b:  1.956141\n",
      "Epoch (      1200 /       5000) cost:  0.000258, W:  7.008534,b:  1.963462\n",
      "Epoch (      1300 /       5000) cost:  0.000179, W:  7.007110,b:  1.969562\n",
      "Epoch (      1400 /       5000) cost:  0.000124, W:  7.005923,b:  1.974643\n",
      "Epoch (      1500 /       5000) cost:  0.000086, W:  7.004934,b:  1.978876\n",
      "Epoch (      1600 /       5000) cost:  0.000060, W:  7.004111,b:  1.982402\n",
      "Epoch (      1700 /       5000) cost:  0.000042, W:  7.003424,b:  1.985340\n",
      "Epoch (      1800 /       5000) cost:  0.000029, W:  7.002853,b:  1.987787\n",
      "Epoch (      1900 /       5000) cost:  0.000020, W:  7.002377,b:  1.989826\n",
      "Epoch (      2000 /       5000) cost:  0.000014, W:  7.001980,b:  1.991524\n",
      "Epoch (      2100 /       5000) cost:  0.000010, W:  7.001649,b:  1.992939\n",
      "Epoch (      2200 /       5000) cost:  0.000007, W:  7.001374,b:  1.994118\n",
      "Epoch (      2300 /       5000) cost:  0.000005, W:  7.001145,b:  1.995100\n",
      "Epoch (      2400 /       5000) cost:  0.000003, W:  7.000954,b:  1.995918\n",
      "Epoch (      2500 /       5000) cost:  0.000002, W:  7.000794,b:  1.996599\n",
      "Epoch (      2600 /       5000) cost:  0.000002, W:  7.000662,b:  1.997167\n",
      "Epoch (      2700 /       5000) cost:  0.000001, W:  7.000551,b:  1.997640\n",
      "Epoch (      2800 /       5000) cost:  0.000001, W:  7.000459,b:  1.998034\n",
      "Epoch (      2900 /       5000) cost:  0.000001, W:  7.000383,b:  1.998362\n",
      "Epoch (      3000 /       5000) cost:  0.000000, W:  7.000319,b:  1.998635\n",
      "Epoch (      3100 /       5000) cost:  0.000000, W:  7.000266,b:  1.998863\n",
      "Epoch (      3200 /       5000) cost:  0.000000, W:  7.000221,b:  1.999053\n",
      "Epoch (      3300 /       5000) cost:  0.000000, W:  7.000184,b:  1.999211\n",
      "Epoch (      3400 /       5000) cost:  0.000000, W:  7.000154,b:  1.999343\n",
      "Epoch (      3500 /       5000) cost:  0.000000, W:  7.000128,b:  1.999452\n",
      "Epoch (      3600 /       5000) cost:  0.000000, W:  7.000107,b:  1.999544\n",
      "Epoch (      3700 /       5000) cost:  0.000000, W:  7.000089,b:  1.999620\n",
      "Epoch (      3800 /       5000) cost:  0.000000, W:  7.000074,b:  1.999683\n",
      "Epoch (      3900 /       5000) cost:  0.000000, W:  7.000062,b:  1.999736\n",
      "Epoch (      4000 /       5000) cost:  0.000000, W:  7.000051,b:  1.999780\n",
      "Epoch (      4100 /       5000) cost:  0.000000, W:  7.000043,b:  1.999817\n",
      "Epoch (      4200 /       5000) cost:  0.000000, W:  7.000036,b:  1.999848\n",
      "Epoch (      4300 /       5000) cost:  0.000000, W:  7.000030,b:  1.999873\n",
      "Epoch (      4400 /       5000) cost:  0.000000, W:  7.000025,b:  1.999894\n",
      "Epoch (      4500 /       5000) cost:  0.000000, W:  7.000021,b:  1.999912\n",
      "Epoch (      4600 /       5000) cost:  0.000000, W:  7.000017,b:  1.999927\n",
      "Epoch (      4700 /       5000) cost:  0.000000, W:  7.000014,b:  1.999939\n",
      "Epoch (      4800 /       5000) cost:  0.000000, W:  7.000012,b:  1.999949\n",
      "Epoch (      4900 /       5000) cost:  0.000000, W:  7.000010,b:  1.999958\n",
      "W:   7.000008\n",
      "b:   1.999965\n",
      "result : \n",
      "[ 8.99997284 15.99998112 22.9999894  29.99999767 37.00000595 44.00001423]\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    # 1. 예측을 먼저 한다.\n",
    "    y_predict = W*X + b\n",
    "    \n",
    "    # 2. 예측한 후 얼마나 잘 예측했는지의 결과...Cost를 알 수 있다.\n",
    "    cost = (np.sum((y_predict-Y)**2)) / n_data # MSE 함수를 코드로 정의\n",
    "    \n",
    "    # 3. 경사하강법 원리에 의해서 W, b 값을 조금씩 보정해 나간다.\n",
    "    W = W - learning_rate * ((y_predict - Y) * X).mean()\n",
    "    b = b - learning_rate * (y_predict - Y).mean()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print('Epoch ({:10d} / {:10d}) cost:{:10f}, W:{:10f},b:{:10f}'.format(i,epochs,cost,W,b))\n",
    "        \n",
    "print('W: {:10f}'.format(W))\n",
    "print('b: {:10f}'.format(b))\n",
    "print('result : ')\n",
    "print(X * W + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
